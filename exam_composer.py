# -*- coding: utf-8 -*-
"""
exam_composer.py
æ•´åˆæµç¨‹ï¼š
1. ä» PDF æå–æ–‡æœ¬å¹¶åˆ†å—
2. ç”Ÿæˆé¡ºåºåµŒå…¥æ•°æ®åº“
3. è°ƒç”¨ LLM ç”Ÿæˆé¢˜ç›®ï¼ˆä»…é¢˜å¹²ï¼‰
4. ä½¿ç”¨ RAG æ£€ç´¢ + LLM ç”Ÿæˆç­”æ¡ˆä¸è§£æ
5. ä¿å­˜å®Œæ•´é¢˜åº“æ–‡ä»¶
"""

import os
import json
from tqdm import tqdm
from pdf_loader import extract_chunks
from embedder import embed_chunks
from question_gen import generate_question
from answer_rag import retrieve_context, answer_with_rag, load_db

# ==== è·¯å¾„é…ç½® ====
PDF_PATH = r"E:\python_prj\åœ°éœ‡å±€å¤ä¹ RAG\data\docs\é˜²éœ‡å‡ç¾çŸ¥è¯†\é˜²éœ‡å‡ç¾åŸºç¡€çŸ¥è¯†.pdf"          # â† ä½ çš„æµ‹è¯• PDF æ–‡ä»¶è·¯å¾„
DB_PATH = r"./data/db/db.jsonl"
OUTPUT_PATH = r"./data/output"
OUTPUT_FILE = os.path.join(OUTPUT_PATH, "exam_result.jsonl")

# ==== å‚æ•°è®¾ç½® ====
QUESTION_INTERVAL = 1    # æ¯éš”å¤šå°‘ä¸ªç‰‡æ®µå‡ºä¸€é“é¢˜
CONTEXT_TOPK = 4         # RAG æ£€ç´¢ç‰‡æ®µæ•°é‡


def main():
    # 0ï¸âƒ£ å‡†å¤‡è¾“å‡ºè·¯å¾„
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    os.makedirs(OUTPUT_PATH, exist_ok=True)

    # 1ï¸âƒ£ æå–æ–‡æœ¬åˆ†å—
    print("ğŸ“– æ­£åœ¨è¯»å–å¹¶åˆ†å— PDF æ–‡æœ¬...")
    chunks = extract_chunks(PDF_PATH)
    print(f"âœ… å…±æå– {len(chunks)} ä¸ªæ–‡æœ¬å—ã€‚")

    # 2ï¸âƒ£ åµŒå…¥æ•°æ®åº“ï¼ˆè‹¥å·²æœ‰å¯è·³è¿‡ï¼‰
    if not os.path.exists(DB_PATH):
        print("âš™ï¸ æ­£åœ¨ç”ŸæˆåµŒå…¥æ•°æ®åº“...")
        embed_chunks(chunks, DB_PATH)
    else:
        print("ğŸ“‚ æ£€æµ‹åˆ°ç°æœ‰åµŒå…¥æ•°æ®åº“ï¼Œè·³è¿‡åµŒå…¥æ­¥éª¤ã€‚")

    # 3ï¸âƒ£ è¯»å–æ•°æ®åº“
    db = load_db(DB_PATH)
    print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®åº“ï¼Œå…± {len(db)} æ¡ã€‚")

    # 4ï¸âƒ£ ç”Ÿæˆé¢˜ç›®å¹¶è§£æ
    results = []
    selected_chunks = chunks[::QUESTION_INTERVAL]
    print(f"ğŸ§© è®¡åˆ’ç”Ÿæˆ {len(selected_chunks)} é“é¢˜ã€‚")

    for chunk in tqdm(selected_chunks, desc="ç”Ÿæˆé¢˜ç›®ä¸è§£æ", ncols=100):
        try:
            # ç”Ÿæˆé¢˜ç›®
            qtext = generate_question(chunk["text"])
            if not qtext.strip():
                continue

            # æ£€ç´¢ä¸Šä¸‹æ–‡
            context = retrieve_context(qtext, db, k=CONTEXT_TOPK)

            # ç”Ÿæˆè§£æ
            ans_text = answer_with_rag(qtext, context)

            results.append({
                "source_index": chunk["index"],
                "question": qtext,
                "context_used": context,
                "answer_and_explanation": ans_text
            })
        except Exception as e:
            print(f"[ERROR] ç¬¬ {chunk['index']} æ®µç”Ÿæˆå¤±è´¥: {e}")

    # 5ï¸âƒ£ ä¿å­˜ç»“æœ
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for item in results:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    print(f"\nğŸ¯ é¢˜åº“ç”Ÿæˆå®Œæˆï¼Œå…± {len(results)} é“é¢˜ï¼Œå·²ä¿å­˜åˆ° {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
